{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the Infrastructure Cluster\n",
    "\n",
    "NEXUS relies on [Apache Solr](http://lucene.apache.org/solr/) to store metadata about tiles and [Apache Cassandra](http://cassandra.apache.org/) to store the floating point array data associated with those tiles. Both Solr and Cassandra are distributed storage systems and can be run in a cluster.  \n",
    "\n",
    "Solr requires [Apache Zookeeper](https://zookeeper.apache.org/) to run in cluster mode (called SolrCloud). This notebook walks through the process of bringing up a 3 node Cassandra cluster, 3 node Zookeeper cluster, and a 3 node SolrCloud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Start One Cassandra Container\n",
    "\n",
    "When initializing a Cassandra cluster, one or more nodes must be designated as a 'seed' node to help bootstrap the internal communication between nodes: [Internode communications (gossip)](http://docs.datastax.com/en/cassandra/2.1/cassandra/architecture/architectureGossipAbout_c.html).\n",
    "\n",
    "Therefore, the first step is to start one Cassandra container so that it can act as the seed node for the rest of our cluster.\n",
    "\n",
    "### TODO\n",
    "1. Navigate to the directory containing the `docker-compose.yml` file for the infrastructure cluster\n",
    "```bash\n",
    "$ cd ~/nexus/esip-workshop/docker/infrastructure\n",
    "```\n",
    "\n",
    "2. Use `docker-compose` to bring up the `cassandra1` container.\n",
    "```bash\n",
    "$ docker-compose up -d cassandra1\n",
    "```\n",
    "\n",
    "3. Wait for the Cassandra node to become ready before continuing. Run the following command to follow the logs for `cassandra1`.\n",
    "```bash\n",
    "$ docker logs -f cassandra1\n",
    "```\n",
    "\n",
    "4. Wait for the Cassandra node to start listening for clients. It should only take a minute or so. Look for this line in the logs:\n",
    "> Starting listening for CQL clients on /0.0.0.0:9042\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Start the Remaining Infrastructure Containers\n",
    "\n",
    "Once the first Cassandra node is running, the rest of the infrastructure cluster can be brought online. The remaining 8 containers in the infrastructure can be started using the `docker-compose` command again.\n",
    "\n",
    "### TODO\n",
    "\n",
    "1. Use `docker-compose` to bring up the remaining containers. __Note__: Make sure you are still in the same directory as Step 1 `~/nexus/esip-workshop/docker/infrastructure`.\n",
    "```bash\n",
    "$ docker-compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify the Infrastructure has Started\n",
    "\n",
    "Now there should be 9 containers running that make up our 3 node Cassandra cluster, 3 node Zookeeper cluster, and 3 node SolrCloud. We can use a variety of commands to verify that our cluster is active and healthy.\n",
    "\n",
    "### TODO\n",
    "\n",
    "1. List all running docker containers.\n",
    "```bash\n",
    "$ docker ps\n",
    "```\n",
    "The output should look simillar to this:\n",
    "<pre style=\"white-space: pre;\">\n",
    "CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                                         NAMES  \n",
    "90d370eb3a4e        nexusjpl/jupyter      \"tini -- start-not...\"   30 hours ago        Up 30 hours         0.0.0.0:8000->8888/tcp                        jupyter  \n",
    "cd0f47fe303d        nexusjpl/nexus-solr   \"docker-entrypoint...\"   30 hours ago        Up 30 hours         8983/tcp                                      solr2  \n",
    "8c0f5c8eeb45        nexusjpl/nexus-solr   \"docker-entrypoint...\"   30 hours ago        Up 30 hours         8983/tcp                                      solr3  \n",
    "27e34d14c16e        nexusjpl/nexus-solr   \"docker-entrypoint...\"   30 hours ago        Up 30 hours         8983/tcp                                      solr1  \n",
    "247f807cb5ec        cassandra:2.2.8       \"/docker-entrypoin...\"   30 hours ago        Up 30 hours         7000-7001/tcp, 7199/tcp, 9042/tcp, 9160/tcp   cassandra3  \n",
    "09cc86a27321        zookeeper             \"/docker-entrypoin...\"   30 hours ago        Up 30 hours         2181/tcp, 2888/tcp, 3888/tcp                  zk1  \n",
    "33e9d9b1b745        zookeeper             \"/docker-entrypoin...\"   30 hours ago        Up 30 hours         2181/tcp, 2888/tcp, 3888/tcp                  zk3  \n",
    "dd29e4d09124        cassandra:2.2.8       \"/docker-entrypoin...\"   30 hours ago        Up 30 hours         7000-7001/tcp, 7199/tcp, 9042/tcp, 9160/tcp   cassandra2  \n",
    "11e57e0c972f        zookeeper             \"/docker-entrypoin...\"   30 hours ago        Up 30 hours         2181/tcp, 2888/tcp, 3888/tcp                  zk2  \n",
    "2292803d942d        cassandra:2.2.8       \"/docker-entrypoin...\"   30 hours ago        Up 30 hours         7000-7001/tcp, 7199/tcp, 9042/tcp, 9160/tcp   cassandra1  \n",
    "</pre>\n",
    "\n",
    "2. Get the Cassandra cluster status by running `nodetool status` inside the `cassandra1` container.\n",
    "```bash\n",
    "$ docker exec cassandra1 nodetool status\n",
    "```\n",
    "You should see 3 cluster nodes:\n",
    "<pre style=\"white-space: pre;\">\n",
    "Datacenter: datacenter1\n",
    "=======================\n",
    "Status=Up/Down\n",
    "|/ State=Normal/Leaving/Joining/Moving\n",
    "--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack\n",
    "UN  172.18.0.2  4.8 GB     256          35.3%             d9a0d273-b11c-41dd-9da1-cb77882f275f  rack1\n",
    "UN  172.18.0.5  4.42 GB    256          33.2%             d68d9ea7-04a0-4eaf-b9c6-333b606bd2b1  rack1\n",
    "UN  172.18.0.7  4.16 GB    256          31.5%             6f8683f9-abf8-4466-87bc-a5faa048956d  rack1\n",
    "</pre>\n",
    "\n",
    "3. Get the status of the SolrCloud by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO Run this cell to get the status of the Solr Cluster. You should see a collection called\n",
    "# 'nexustiles' with 3 shards spread across all 3 nodes.\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.get('http://solr1:8983/solr/admin/collections?action=clusterstatus&wt=json')\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have sucessfully started up the NEXUS infrastructure. Your EC2 instance now has 9 containers running:\n",
    "\n",
    "![Infrastructure](img/ec2-containers-infrastructure.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
